{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "NUM_LABELS = 200  # The number of labels. 40\n",
    "BATCH_SIZE = 5000  # The number of training examples to use per training step  3000\n",
    "DM_min,DM_max = 0.05176, 20.0625 # -0.9..20\n",
    "training_epochs = 1200  #1950 # 40\n",
    "#display_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 56 # 1st layer num features # 56\n",
    "n_hidden_2 = 56 # 2nd layer num features # 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ToClass(X, NBIN, XMIN,XMAX):\n",
    "    labels = (np.array(X-XMIN)/(XMAX-XMIN)*NBIN).astype(int)\n",
    "    labels[labels < 0] = 0\n",
    "    labels[labels >= NBIN] = NBIN-1\n",
    "    return labels\n",
    "\n",
    "def ToDM(X,NBIN,XMIN,XMAX):\n",
    "    TEMP1 = (X*(XMAX-XMIN)/NBIN) + XMIN\n",
    "    return TEMP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data(filename):\n",
    "\n",
    "    # Arrays to hold the labels and feature vectors.\n",
    "    labels = []\n",
    "    fvecs = []\n",
    "\n",
    "    # Iterate over the rows, splitting the label from the features. Convert labels\n",
    "    # to integers and features to floats.\n",
    "    for line in file(filename):\n",
    "        row = line.split(\" \")\n",
    "        labels.append(int(row[0]))\n",
    "        fvecs.append([float(x) for x in row[1:]])\n",
    "\n",
    "    # Convert the array of float arrays into a numpy float matrix.\n",
    "    fvecs_np = np.matrix(fvecs).astype(np.float32)\n",
    "\n",
    "    # Convert the array of int labels into a numpy array.\n",
    "    labels_np = np.array(labels).astype(dtype=np.uint16)\n",
    "    #DM_np = ToDM(labels_np, NUM_LABELS, DM_min, DM_max)\n",
    "\n",
    "    # Convert the int numpy array into a one-hot matrix.\n",
    "    labels_onehot = (np.arange(NUM_LABELS) == labels_np[:, None]).astype(np.float32)\n",
    "\n",
    "    # Return a pair of the feature matrix and the one-hot label matrix.\n",
    "    return fvecs_np,labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data2(filename):\n",
    "    DM = []\n",
    "    Cond = []\n",
    "    \n",
    "    for line in file(filename):\n",
    "        row = line.split(\" \")\n",
    "        Cond.append(int(row[0]))\n",
    "        DM.append(float(row[1]))\n",
    "        \n",
    "    DM_np = np.array(DM).astype(dtype=np.float32)\n",
    "    COND = np.array(Cond).astype(dtype=np.uint16)\n",
    "    return COND, DM_np\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(_X, _weights, _biases):\n",
    "    #Hidden layer with RELU activation\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1'])) \n",
    "    #Hidden layer with RELU activation\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2'])) \n",
    "    #layer_2_drop = tf.nn.dropout(layer_2, keep_prob)\n",
    "    return tf.matmul(layer_2, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract it into numpy arrays.\n",
    "train_data, train_labels = extract_data('RANDOM_SAMPLE_BIN.txt') # Datos de entrenamiento\n",
    "test_data, test_labels = extract_data('TESTDATA.txt')            # Datos de test en labels\n",
    "Condition, test_DM = extract_data2('TEST_DELTAS.txt')            # Datos de test en DarkMatter y condicion True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the shape of the training data.\n",
    "train_size,num_features = train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias \n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_features, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, NUM_LABELS]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([NUM_LABELS]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", shape=[None, num_features])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, NUM_LABELS])\n",
    "\n",
    "# The output layer.\n",
    "y = tf.nn.softmax(multilayer_perceptron(x, weights, biases))\n",
    "    \n",
    "# Optimization.\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.0001).minimize(cross_entropy) # 0.0001\n",
    "    \n",
    "# Evaluation.\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "output = tf.argmax(y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "with tf.Session() as s:\n",
    "        # Run all the initializers to prepare the trainable parameters.\n",
    "        tf.initialize_all_variables().run()\n",
    "        # Iterate and train.\n",
    "        for step in xrange(training_epochs * train_size // BATCH_SIZE):\n",
    "\n",
    "            offset = (step * BATCH_SIZE) % train_size\n",
    "            batch_data = train_data[offset:(offset + BATCH_SIZE), :]\n",
    "            batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "            train_step.run(feed_dict={x: batch_data, y_: batch_labels})\n",
    "        \n",
    "            #if step % display_step == 0: \n",
    "            #    print \"Step:\",'%i' % step,\"Accuracy:\", accuracy.eval(feed_dict={x: test_data, y_: test_labels})\n",
    "        \n",
    "        Pred = output.eval(feed_dict={x: test_data})\n",
    "        print \"Test Accuracy:\", accuracy.eval(feed_dict={x: test_data, y_: test_labels})\n",
    "        #for i in range(len(Pred)):\n",
    "        #   print np.where(test_labels[i])[0][0],Pred[i]\n",
    "\n",
    "        #print \"Test Accuracy:\", accuracy.eval(feed_dict={x: test_data, y_: test_labels})\n",
    "        \n",
    "print(\"--- %3fs: loaded ---\" % (time.time() - start_time))   \n",
    "Pred_DM = ToDM(Pred,NUM_LABELS,DM_min,DM_max)\n",
    "np.savetxt('Exit_01.txt', np.array([Condition, test_DM, Pred_DM]).T, fmt= ['%i','%.5f','%.5f'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print np.where(test_labels[i])[0][0],Pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAINING EPOCH = 540   BATCH SIZE = 5000   HIDDEN LAYERS = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pred_DM = ToDM(Pred,NUM_LABELS,DM_min,DM_max)\n",
    "np.savetxt('Exit_01.txt', np.array([Condition, test_DM,Pred_DM]).T, fmt= ['%i','%.5f','%.5f'] )\n",
    "#for i in range(200,300):\n",
    "#    print np.where(test_labels[i])[0][0],Pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy import stats\n",
    "import pylab as pl\n",
    "import pylab\n",
    "from pylab import *\n",
    "from matplotlib import rc\n",
    "import readcol as lector\n",
    "import numpy as np\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 13})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cond, delta_DM, delta_ANN = lector.readcol(\"Exit_01.txt\",twod = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cond = Cond.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ANN_True = delta_ANN[Cond == True]\n",
    "ANN_False = delta_ANN[Cond == False]\n",
    "delta_DM_True = delta_DM[Cond == True]\n",
    "delta_DM_False = delta_DM[Cond == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ====== RESIDUAL PLOT ========\n",
    "Res_ANN_True = (ANN_True - delta_DM_True) / delta_DM_True\n",
    "Res_ANN_False = (ANN_False - delta_DM_False) / delta_DM_False\n",
    "RESIDUO = (delta_ANN - delta_DM) / delta_DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264849 264849\n"
     ]
    }
   ],
   "source": [
    "print len(RESIDUO), len(Res_ANN_False)+ len(Res_ANN_True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxval, minval = delta_DM.max(), delta_DM.min()\n",
    "num_bins = 150\n",
    "delta = (maxval-minval) / num_bins\n",
    "i,l  = 0,0\n",
    "\n",
    "labels_True = ToClass(delta_DM_True, num_bins, minval, maxval) # delta_DM_True\n",
    "labels_False = ToClass(delta_DM_False, num_bins, minval, maxval) # delta_DM_False\n",
    "bin_list_True = []\n",
    "bin_list_False = []\n",
    "\n",
    "while i < num_bins:\n",
    "    r = np.any(labels_True == i)\n",
    "    if r == True:\n",
    "        bin_list_True.append(i)\n",
    "    i += 1    \n",
    "    \n",
    "while l < num_bins:\n",
    "    r = np.any(labels_False == l)\n",
    "    if r == True:\n",
    "        bin_list_False.append(l)\n",
    "    l += 1    \n",
    "\n",
    "bin_list_errobar_T = [k+1 for k in np.arange(0,num_bins,5)]\n",
    "bin_list_errobar_F = [k+3 for k in np.arange(0,num_bins,5)]    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_0 = minval + delta/2\n",
    "t = np.arange(maxval)\n",
    "bins_True = np.array([ a_0 + delta*n for n in bin_list_True])\n",
    "bins_False = np.array([ a_0 + delta*n for n in bin_list_False])\n",
    "median_True = np.array([np.median((Res_ANN_True[labels_True == j])) for j in bin_list_True]) # ANN_True\n",
    "median_False = np.array([np.median((Res_ANN_False[labels_False == j])) for j in bin_list_False]) # ANN_False\n",
    "#running_err_down_T    = [(np.sort(ANN_True[labels_True == k]))[(len(ANN_True[labels_True == k]))/5] for k in bin_list_errobar_T]\n",
    "#running_err_up_T      = [(np.sort(ANN_True[labels_True == l]))[(4*len(ANN_True[labels_True == l]))/5] for l in bin_list_errobar_T]\n",
    "#running_err_down_F    = [(np.sort(ANN_False[labels_False == k]))[(len(ANN_False[labels_False == k]))/5] for k in bin_list_errobar_F]\n",
    "#running_err_up_F      = [(np.sort(ANN_False[labels_False == l]))[(4*len(ANN_False[labels_False == l]))/5] for l in bin_list_errobar_F]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ========= RESIDUAL PLOT =========\n",
    "plt.plot(delta_DM, RESIDUO, 'o', color = '#e0ffff', markersize = .5) #,alpha =.55, markersize = .5\n",
    "plt.plot(t,t*0,'--', lw = 2.5,color = 'green')\n",
    "plt.plot(bins_True,median_True,color='red',linestyle = '-',lw=2.0,alpha=.7,label = r\"Median $\\left(\\{\\delta_i\\}<\\delta_c\\right)$\") \n",
    "plt.plot(bins_False,median_False,color='blue',linestyle = '-',lw=2.0,alpha=.7,label = r\"Median $\\left(\\delta_i > \\delta_c\\right)$\") \n",
    "plt.xlabel(r\"$\\delta_{DM} + 1 $\", fontsize = 16)\n",
    "plt.ylabel(r\"Residuals\", fontsize = 16) # $\\frac{\\delta_{ANN} -\\delta_{DM}}{\\delta_{DM} +1 } $\n",
    "plt.legend()\n",
    "plt.axis([0,20.0,-1,2.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/pymodules/python2.7/matplotlib/collections.py:548: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(delta_DM, delta_ANN,'o', color = '#e0ffff', markersize = .5, alpha = .1) #,alpha =.55, markersize = .5\n",
    "plt.plot(t,t,'--',color = '#228B22',lw=2,alpha=.7, label = r\"$\\delta_{ANN} = \\delta_{DM}$\")\n",
    "plt.xlabel(r\"$\\delta_{DM} + 1 $\", fontsize = 16)\n",
    "plt.ylabel(r\"$\\delta_{ANN} + 1 $\", fontsize = 16) #48d1cc\n",
    "plt.title(r\"\")\n",
    "plt.axis([0,3.5,0,3.5])\n",
    "plt.plot(bins_True,median_True,color='red',linestyle = '-',lw=2.5,alpha=.7,label = r\"Median$\\left(\\{\\delta_i\\}<\\delta_c\\right)$\") \n",
    "plt.plot(bins_False,median_False,color='blue',linestyle = '-',lw=2.5,alpha=.7,label = r\"Median$\\left(\\delta_i > \\delta_c\\right)$\") \n",
    "plt.errorbar(bins_True[bin_list_errobar_T],median_True[bin_list_errobar_T], yerr = [median_True[bin_list_errobar_T]-running_err_down_T,running_err_up_T-median_True[bin_list_errobar_T]],alpha = .8, fmt = None, elinewidth = 1.5, ecolor = 'red')\n",
    "plt.errorbar(bins_False[bin_list_errobar_F],median_False[bin_list_errobar_F], yerr = [median_False[bin_list_errobar_F]-running_err_down_F,running_err_up_F-median_False[bin_list_errobar_F]],alpha = .8, fmt = None, elinewidth = 1.5, ecolor = 'blue')\n",
    "pylab.legend(loc='lower right',frameon=True, prop={'size':14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ================================================ SAVE DATA ===========================================================\n",
    "\n",
    "DM_train = []\n",
    "Halos_train = []\n",
    "\n",
    "DM_test = []\n",
    "Halos_test = []\n",
    "\n",
    "Condition = []\n",
    "\n",
    "for line in file('RANDOM_SAMPLE.txt'):\n",
    "        row = line.split(\" \")\n",
    "        DM_train.append(float(row[0]))\n",
    "        Halos_train.append([float(x) for x in row[1:]])\n",
    "\n",
    "for line in file('test_deltas.txt'):\n",
    "        row = line.split(\" \")\n",
    "        Condition.append(int(row[0]))\n",
    "        DM_test.append(float(row[1]))\n",
    "        Halos_test.append([float(x) for x in row[2:]])\n",
    "    \n",
    "        \n",
    "DM_train_np = np.array(DM_train).astype(dtype = np.float32) \n",
    "DM_test_np = np.array(DM_test).astype(dtype = np.float32)\n",
    "\n",
    "Halos_train_np = np.array(Halos_train).astype(dtype= np.float32) # GUARDAR\n",
    "Halos_test_np = np.array(Halos_test).astype(dtype = np.float32)\n",
    "\n",
    "Condition_np = np.array(Condition)\n",
    "\n",
    "minval, maxval =  DM_train_np.min(), DM_train_np.max()\n",
    "\n",
    "mask = ( DM_test_np >= minval ) & (DM_test_np <= maxval)\n",
    "Halos_test_np = Halos_test_np[mask]\n",
    "Condition_np = Condition_np[mask]\n",
    "DM_test_np = DM_test_np[mask]\n",
    "\n",
    "np.savetxt('TEST_DELTAS.txt', np.array([Condition_np, DM_test_np]).T, fmt = ['%i','%.5f'] )\n",
    "\n",
    "labels_train =  ToClass(DM_train_np, NUM_LABELS, minval, maxval) # GUARDAR\n",
    "labels_test  =  ToClass(DM_test_np, NUM_LABELS, minval, maxval) # GUARDAR\n",
    "\n",
    "print minval\n",
    "print maxval\n",
    "\n",
    "del(DM_test_np,DM_test, DM_train_np)\n",
    "del DM_train[:]\n",
    "del Halos_train[:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp1 = np.zeros((len(labels_train),28)) \n",
    "temp2 = np.zeros((len(labels_test),28))\n",
    "\n",
    "for i in range(len(labels_train)):\n",
    "    temp1[i] = np.concatenate(([labels_train[i]], Halos_train_np[i])) # Halos_train\n",
    "\n",
    "for j in range(len(labels_test)):\n",
    "    temp2[j] = np.concatenate(([labels_test[j]], Halos_test_np[j])) # Halos test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formatt = []\n",
    "formatt.append('%i')\n",
    "for i in range(27):\n",
    "    formatt.append('%.5f')\n",
    "\n",
    "#np.savetxt('RANDOM_SAMPLE_BIN.txt', temp1, fmt = formatt)\n",
    "np.savetxt('TESTDATA.txt', temp2, fmt = formatt)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
